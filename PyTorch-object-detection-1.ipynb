{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection with PyTorch and Mask R-CNN \n",
    "\n",
    "In this tutorial, you will finetune a pre-trained [Mask R-CNN](https://arxiv.org/abs/1703.06870) model on images from the [Penn-Fudan Database for Pedestrian Detection and Segmentation](https://www.cis.upenn.edu/~jshi/ped_html/). The dataset has 170 images with 345 instances of pedestrians.\n",
    "\n",
    "## Prerequisities\n",
    "\n",
    "- If you are using an Azure Machine Learning Notebook VM, your environment already meets these prerequisites. Otherwise, go through the [Configuration](https://docs.microsoft.com/azure/machine-learning/how-to-configure-environment) steps to install the Azure Machine Learning Python SDK and [create an Azure ML Workspace](https://docs.microsoft.com/azure/machine-learning/how-to-manage-workspace#create-a-workspace).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint hyperdrive = azureml.train.hyperdrive:HyperDriveRun._from_run_dto with exception (azureml-core 1.0.65.1 (/home/gopalv/miniconda3/envs/azureml/lib/python3.6/site-packages), Requirement.parse('azureml-core==1.0.69.*')).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.PipelineRun = azureml.pipeline.core.run:PipelineRun._from_dto with exception (azureml-core 1.0.65.1 (/home/gopalv/miniconda3/envs/azureml/lib/python3.6/site-packages), Requirement.parse('azureml-core==1.0.69.*')).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.ReusedStepRun = azureml.pipeline.core.run:StepRun._from_reused_dto with exception (azureml-core 1.0.65.1 (/home/gopalv/miniconda3/envs/azureml/lib/python3.6/site-packages), Requirement.parse('azureml-core==1.0.69.*')).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.StepRun = azureml.pipeline.core.run:StepRun._from_dto with exception (azureml-core 1.0.65.1 (/home/gopalv/miniconda3/envs/azureml/lib/python3.6/site-packages), Requirement.parse('azureml-core==1.0.69.*')).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.0.65\n"
     ]
    }
   ],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostics\n",
    "\n",
    "Opt-in diagnostics for better experience, quality, and security in future releases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turning diagnostics collection on. \n"
     ]
    }
   ],
   "source": [
    "from azureml.telemetry import set_diagnostics_collection\n",
    "\n",
    "set_diagnostics_collection(send_diagnostics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize a workspace\n",
    "\n",
    "Initialize a [workspace](https://docs.microsoft.com/en-us/azure/machine-learning/concept-workspace) object from the existing workspace you created in the Prerequisites step. `Workspace.from_config()` creates a workspace object from the details stored in `config.json`, using the [from_config()](https://docs.microsoft.com/python/api/azureml-core/azureml.core.workspace(class)?view=azure-ml-py#from-config-path-none--auth-none---logger-none---file-name-none-) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: gopalv-ws\n",
      "Azure region: westus2\n",
      "Subscription id: 15ae9cb6-95c1-483d-a0e3-b1a1a3b06324\n",
      "Resource group: aifxdemo\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create or attach existing Azure ML Managed Compute\n",
    "\n",
    "You will need to create a [compute target](https://docs.microsoft.com/azure/machine-learning/concept-compute-target) for training your model. In this tutorial, we use [Azure ML managed compute](https://docs.microsoft.com/azure/machine-learning/how-to-set-up-training-targets#amlcompute) for our remote training compute resource. Specifically, the below code creates a `STANDARD_NC6` GPU cluster that autoscales from 0 to 4 nodes.\n",
    "\n",
    "**Creation of Compute takes approximately 5 minutes.** If the Aauzre ML Compute with that name is already in your workspace, this code will skip the creation process. \n",
    "\n",
    "As with other Azure servies, there are limits on certain resources associated with the Azure Machine Learning service. Please read [this article](https://docs.microsoft.com/azure/machine-learning/how-to-manage-quotas) on the default limits and how to request more quota.\n",
    "\n",
    "> Note that the below code creates GPU compute. If you instead want to create CPU compute, provide a different VM size to the `vm_size` parameter, such as `STANDARD_D2_V2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['demouser', 'demo@pass123']\n",
      "Found existing compute target.\n",
      "{'currentNodeCount': 1, 'targetNodeCount': 1, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 1, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2020-03-05T15:13:04.911000+00:00', 'errors': None, 'creationTime': '2020-03-05T14:55:28.441267+00:00', 'modifiedTime': '2020-03-05T15:05:30.544256+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_NC6'}\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# Avoid committing username and password in Git history, useful for debugging GPU usage\n",
    "\n",
    "login_strings = []\n",
    "with open('username-pass.txt', 'r') as file:\n",
    "    for line in file.readlines():\n",
    "        login_strings.append(line.rstrip('\\n'))\n",
    "\n",
    "print(login_strings)\n",
    "\n",
    "# choose a name for your cluster\n",
    "cluster_name = 'gpu-cluster'\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing compute target.')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC6', \n",
    "                                                           max_nodes=4,\n",
    "                                                           admin_username=login_strings[0],\n",
    "                                                           admin_user_password=login_strings[1])\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "    compute_target.wait_for_completion(show_output=True)\n",
    "\n",
    "# use get_status() to get a detailed status for the current cluster. \n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model on the remote compute\n",
    "\n",
    "### Create a project directory\n",
    "Create a directory that will contain all the code from your local machine that you will need access to on the remote resource. This includes the training script an any additional files your training script depends on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: './pytorch-peds'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6eeb015bacc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mproject_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./pytorch-peds'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/azureml/lib/python3.6/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: './pytorch-peds'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "project_folder = './pytorch-peds'\n",
    "\n",
    "try:\n",
    "    os.makedirs(project_folder, exist_ok=False)\n",
    "except FileExistsError:\n",
    "    print(f'project folder {project_folder} exists, moving on...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possibly helpful: [this link](https://github.com/drabastomek/GTC/blob/master/SJ_2020/workshop/1_Setup/Setup.ipynb), and this sample dockerfile from Jordan:\n",
    "\n",
    "```\n",
    "FROM mcr.microsoft.com/azureml/base-gpu:intelmpi2018.3-cuda9.0-cudnn7-ubuntu16.04\n",
    "\n",
    "# Install Horovod, temporarily using CUDA stubsddd \n",
    "RUN ldconfig /usr/local/cuda/lib64/stubs && \\     \n",
    "# Install AzureML SDK     \n",
    "pip install --no-cache-dir azureml-defaults && \\     \n",
    "# Install PyTorch     \n",
    "pip install --no-cache-dir tensorflow==2.0.0b1 tensorflow-gpu==2.0.0b1 keras==2.0.8 matplotlib==3.0.3 seaborn==0.9.0 requests==2.21.0 bs4==0.0.1 imageio==2.5.0 sklearn pandas==0.24.2 numpy==1.16.2 hickle==3.4.3 && \\     \n",
    "# Install Horovod     \n",
    "pip install --no-cache-dir horovod==0.13.5 && \\     ldconfig\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy training script and dependencies into project directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./pytorch-peds/script.py'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.copy('data.py', project_folder)\n",
    "shutil.copy('model.py', project_folder)\n",
    "shutil.copy('script.py', project_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/pytorch/vision.git\n",
    "\n",
    "# !git checkout v0.3.0\n",
    "\n",
    "# %cd vision\n",
    "# !cp references/detection/utils.py ../\n",
    "# !cp references/detection/transforms.py ../\n",
    "# !cp references/detection/coco_eval.py ../\n",
    "# !cp references/detection/engine.py ../\n",
    "# !cp references/detection/coco_utils.py ../\n",
    "# %cd ..\n",
    "\n",
    "# files_to_copy = ['utils', 'transforms', 'coco_eval', 'engine', 'coco_utils']\n",
    "# for file in files_to_copy:\n",
    "#     shutil.copy('./vision/references/detection/'+ file + '.py', project_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data and upload to Azure blob storage\n",
    "\n",
    "First we download the sample dataset, and extract the images into local storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation  PNGImages  PedMasks  added-object-list.txt\treadme.txt\r\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "from zipfile import ZipFile\n",
    "\n",
    "data_file = './test.zip'\n",
    "\n",
    "urllib.request.urlretrieve('https://www.cis.upenn.edu/~jshi/ped_html/PennFudanPed.zip', data_file)\n",
    "zip = ZipFile(file=data_file)\n",
    "zip.extractall()\n",
    "!ls PennFudanPed/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we upload the data files to the datastore associated with this workspace, so that we can access them during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workspaceblobstore AzureBlob gopalvws3790775563 azureml-blobstore-e47496c6-9688-4277-a05b-ceb722514b9d\n",
      "Uploading an estimated of 512 files\n",
      "Target already exists. Skipping upload for data/added-object-list.txt\n",
      "Target already exists. Skipping upload for data/readme.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00001.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00002.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00003.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00004.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00005.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00006.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00007.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00008.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00009.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00010.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00011.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00012.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00013.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00014.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00015.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00016.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00017.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00018.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00019.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00020.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00021.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00022.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00023.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00024.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00025.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00026.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00027.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00028.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00029.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00030.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00031.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00032.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00033.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00034.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00035.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00036.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00037.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00038.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00039.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00040.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00041.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00042.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00043.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00044.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00045.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00046.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00047.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00048.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00049.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00050.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00051.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00052.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00053.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00054.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00055.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00056.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00057.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00058.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00059.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00060.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00061.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00062.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00063.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00064.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00065.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00066.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00067.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00068.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00069.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00070.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00071.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00072.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00073.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00074.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00001.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00002.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00003.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00004.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00005.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00006.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00007.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00008.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00009.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00010.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00011.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00012.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00013.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00014.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00015.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00016.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00017.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00018.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00019.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00020.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00021.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00022.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00023.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00024.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00025.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00026.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00027.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00028.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00029.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00030.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target already exists. Skipping upload for data/Annotation/PennPed00031.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00032.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00033.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00034.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00035.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00036.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00037.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00038.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00039.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00040.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00041.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00042.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00043.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00044.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00045.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00046.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00047.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00048.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00049.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00050.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00051.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00052.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00053.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00054.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00055.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00056.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00057.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00058.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00059.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00060.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00061.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00062.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00063.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00064.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00065.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00066.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00067.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00068.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00069.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00070.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00071.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00072.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00073.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00074.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00075.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00076.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00077.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00078.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00079.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00080.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00081.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00082.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00083.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00084.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00085.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00086.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00087.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00088.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00089.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00090.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00091.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00092.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00093.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00094.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00095.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00096.txt\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00001.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00002.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00003.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00004.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00005.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00006.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00007.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00008.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00009.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00010.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00011.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00012.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00013.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00014.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00015.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00016.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00017.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00018.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00019.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00020.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00021.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00022.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00023.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00024.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00025.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00026.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00027.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00028.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00029.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00030.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00031.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00032.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00033.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00034.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00035.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00036.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00037.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00038.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00039.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00040.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00041.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00042.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00043.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00044.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00045.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00046.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00047.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00048.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00049.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00050.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00051.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00052.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00053.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00054.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00055.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00056.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00057.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00058.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00059.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00060.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00061.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00062.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00063.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00064.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00065.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00066.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00067.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00068.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00069.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00070.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00071.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00072.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00073.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00074.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00001.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00002.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00003.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00004.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00005.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00006.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00007.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00008.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00009.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00010.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00011.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00012.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00013.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00014.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00015.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00016.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00017.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00018.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00019.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00020.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00021.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00022.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00023.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00024.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00025.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00026.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00027.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00028.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00029.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00030.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00031.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00032.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00033.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00034.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00035.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00036.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00037.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00038.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00039.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00040.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00041.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00042.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00043.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00044.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00045.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00046.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00047.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00048.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00049.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00050.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00051.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00052.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00053.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00054.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00055.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00056.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00057.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00058.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00059.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00060.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00061.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00062.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00063.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00064.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00065.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00066.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00067.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00068.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00069.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00070.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00071.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00072.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00073.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00074.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00075.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00076.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00077.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00078.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00079.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00080.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00081.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target already exists. Skipping upload for data/PNGImages/PennPed00082.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00083.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00084.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00085.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00086.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00087.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00088.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00089.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00090.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00091.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00092.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00093.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00094.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00095.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00096.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00001_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00002_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00003_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00004_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00005_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00006_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00007_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00008_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00009_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00010_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00011_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00012_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00013_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00014_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00015_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00016_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00017_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00018_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00019_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00020_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00021_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00022_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00023_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00024_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00025_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00026_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00027_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00028_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00029_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00030_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00031_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00032_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00033_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00034_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00035_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00036_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00037_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00038_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00039_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00040_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00041_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00042_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00043_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00044_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00045_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00046_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00047_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00048_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00049_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00050_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00051_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00052_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00053_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00054_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00055_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00056_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00057_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00058_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00059_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00060_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00061_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00062_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00063_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00064_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00065_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00066_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00067_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00068_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00069_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00070_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00071_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00072_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00073_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00074_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00001_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00002_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00003_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00004_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00005_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00006_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00007_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00008_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00009_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00010_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00011_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00012_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00013_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00014_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00015_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00016_mask.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target already exists. Skipping upload for data/PedMasks/PennPed00017_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00018_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00019_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00020_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00021_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00022_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00023_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00024_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00025_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00026_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00027_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00028_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00029_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00030_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00031_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00032_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00033_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00034_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00035_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00036_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00037_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00038_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00039_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00040_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00041_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00042_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00043_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00044_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00045_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00046_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00047_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00048_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00049_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00050_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00051_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00052_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00053_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00054_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00055_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00056_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00057_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00058_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00059_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00060_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00061_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00062_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00063_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00064_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00065_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00066_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00067_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00068_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00069_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00070_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00071_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00072_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00073_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00074_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00075_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00076_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00077_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00078_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00079_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00080_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00081_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00082_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00083_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00084_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00085_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00086_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00087_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00088_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00089_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00090_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00091_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00092_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00093_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00094_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00095_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00096_mask.png\n",
      "Uploaded 0 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_8085127ad2444eb4856c44cfa99c5f74"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the default datastore\n",
    "ds = ws.get_default_datastore()\n",
    "print(ds.name, ds.datastore_type, ds.account_name, ds.container_name)\n",
    "\n",
    "ds.upload('./PennFudanPed', target_path='data', overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register a dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"source\": [\n",
       "    \"('workspaceblobstore', 'data')\"\n",
       "  ],\n",
       "  \"definition\": [\n",
       "    \"GetDatastoreFiles\"\n",
       "  ],\n",
       "  \"registration\": {\n",
       "    \"name\": \"penn_ds\",\n",
       "    \"version\": 1,\n",
       "    \"description\": \"Penn Fudan pedestrian data\",\n",
       "    \"workspace\": \"Workspace.create(name='gopalv-ws', subscription_id='15ae9cb6-95c1-483d-a0e3-b1a1a3b06324', resource_group='aifxdemo')\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "datastore_paths = [(ds, 'data')]\n",
    "penn_ds = Dataset.File.from_files(path=datastore_paths)\n",
    "penn_ds.register(workspace=ws,\n",
    "                 name='penn_ds',\n",
    "                 description='Penn Fudan pedestrian data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment_name = 'pytorch-peds'\n",
    "experiment = Experiment(ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify dependencies with a custom Dockerfile\n",
    "\n",
    "There are a number of ways to [use environments](https://docs.microsoft.com/azure/machine-learning/how-to-use-environments) for specifying dependencies during model training. In this case, we use a custom Dockerfile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 'gpu_support' is no longer necessary; AzureML now automatically detects and uses nvidia docker extension when it is available. It will be removed in a future release.\n",
      "WARNING - 'gpu_support' is no longer necessary; AzureML now automatically detects and uses nvidia docker extension when it is available. It will be removed in a future release.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Environment\n",
    "\n",
    "my_env = Environment(name='maskr-docker')\n",
    "my_env.docker.enabled = True\n",
    "with open(\"dockerfiles/Dockerfile1\", \"r\") as f:\n",
    "    dockerfile_contents_of_your_base_image=f.read()\n",
    "my_env.docker.base_dockerfile=dockerfile_contents_of_your_base_image \n",
    "my_env.docker.base_image = None\n",
    "my_env.docker.gpu_support = True\n",
    "my_env.python.interpreter_path = '/opt/miniconda/bin/python'\n",
    "my_env.python.user_managed_dependencies = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a ScriptRunConfig\n",
    "\n",
    "Use the [ScriptRunConfig](https://docs.microsoft.com/python/api/azureml-core/azureml.core.scriptrunconfig?view=azure-ml-py) class to define your run. Specify the source driectory, compute target, and environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.dnn import PyTorch\n",
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "# follow pattern from here: https://docs.microsoft.com/en-us/azure/machine-learning/how-to-use-environments#use-environments-for-training\n",
    "\n",
    "# Add training script to run config\n",
    "runconfig = ScriptRunConfig(source_directory=project_folder, script=\"script.py\")\n",
    "\n",
    "# Attach compute target to run config\n",
    "runconfig.run_config.target = cluster_name\n",
    "\n",
    "# Uncomment the line below if you want to try this locally first\n",
    "#runconfig.run_config.target = \"local\"\n",
    "\n",
    "# Attach environment to run config\n",
    "runconfig.run_config.environment = my_env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit your run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'runId': 'pytorch-peds_1583423518_e19690b0', 'target': 'gpu-cluster', 'status': 'Starting', 'properties': {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': '94227f40-71ba-4d80-b955-2197961d046a', 'azureml.git.repository_uri': 'git@github.com:gvashishtha/pytorch-object.git', 'mlflow.source.git.repoURL': 'git@github.com:gvashishtha/pytorch-object.git', 'azureml.git.branch': 'docker', 'mlflow.source.git.branch': 'docker', 'azureml.git.commit': '79200f8e321c29fb8d8d11df96b267942a744aa9', 'mlflow.source.git.commit': '79200f8e321c29fb8d8d11df96b267942a744aa9', 'azureml.git.dirty': 'False', 'AzureML.DerivedImageName': 'azureml/azureml_9125fd9b495cfdec8f7bf56c6d28d91d'}, 'inputDatasets': [], 'runDefinition': {'script': 'script.py', 'useAbsolutePath': False, 'arguments': [], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'gpu-cluster', 'dataReferences': {}, 'data': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'environment': {'name': 'maskr-docker', 'version': 'Autosave_2020-02-29T00:36:31Z_cd1e72fb', 'python': {'interpreterPath': '/opt/miniconda/bin/python', 'userManagedDependencies': True, 'condaDependencies': {'name': 'project_environment', 'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults']}], 'channels': ['conda-forge']}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': None, 'baseDockerfile': '# From https://github.com/microsoft/AzureML-BERT/blob/master/finetune/PyTorch/dockerfile\\n\\nFROM mcr.microsoft.com/azureml/base-gpu:openmpi3.1.2-cuda10.1-cudnn7-ubuntu18.04\\n\\nRUN apt update && apt install git -y && rm -rf /var/lib/apt/lists/*\\n\\nRUN /opt/miniconda/bin/conda update -n base -c defaults conda\\nRUN /opt/miniconda/bin/conda install -y cython=0.29.15 numpy=1.18.1\\nRUN /opt/miniconda/bin/conda install -y pytorch=1.4 torchvision=0.5.0 -c pytorch\\n\\n# Install cocoapi, required for drawing bounding boxes\\nRUN git clone https://github.com/cocodataset/cocoapi.git && cd cocoapi/PythonAPI && python setup.py build_ext install\\n\\nRUN pip install azureml-defaults\\nRUN pip install \"azureml-dataprep[fuse]\"\\nRUN pip install pandas pyarrow\\n', 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}}, 'logFiles': {}}\n"
     ]
    }
   ],
   "source": [
    "# Submit run \n",
    "run = experiment.submit(runconfig)\n",
    "\n",
    "# to get more details of your run\n",
    "print(run.get_details())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor your run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97cf91bbdd294344ba2c6350e2b2e9a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': True, 'log_level': 'INFO', 's…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: pytorch-peds_1583423518_e19690b0\n",
      "Web View: https://mlworkspace.azure.ai/portal/subscriptions/15ae9cb6-95c1-483d-a0e3-b1a1a3b06324/resourceGroups/aifxdemo/providers/Microsoft.MachineLearningServices/workspaces/gopalv-ws/experiments/pytorch-peds/runs/pytorch-peds_1583423518_e19690b0\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_c02c232e1b37289a0a6f8f779158f57039786cf0db14e945cee0ecc355e45111_d.txt\n",
      "========================================================================================================================\n",
      "\n",
      "2020-03-05T15:56:03Z Starting output-watcher...\n",
      "2020-03-05T15:56:03Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_9125fd9b495cfdec8f7bf56c6d28d91d\n",
      "7ddbc47eeb70: Pulling fs layer\n",
      "c1bbdc448b72: Pulling fs layer\n",
      "8c3b70e39044: Pulling fs layer\n",
      "45d437916d57: Pulling fs layer\n",
      "d8f1569ddae6: Pulling fs layer\n",
      "85386706b020: Pulling fs layer\n",
      "ee9b457b77d0: Pulling fs layer\n",
      "be4f3343ecd3: Pulling fs layer\n",
      "30b4effda4fd: Pulling fs layer\n",
      "b398e882f414: Pulling fs layer\n",
      "f2e1f2321196: Pulling fs layer\n",
      "1e87b0a17e1a: Pulling fs layer\n",
      "e446a9769f53: Pulling fs layer\n",
      "45d437916d57: Waiting\n",
      "d8f1569ddae6: Waiting\n",
      "85386706b020: Waiting\n",
      "4493432064f7: Pulling fs layer\n",
      "ee9b457b77d0: Waiting\n",
      "6aadf6f91a8d: Pulling fs layer\n",
      "66d0708eeaf3: Pulling fs layer\n",
      "be4f3343ecd3: Waiting\n",
      "5952336ab5bb: Pulling fs layer\n",
      "30b4effda4fd: Waiting\n",
      "31c18b4a9955: Pulling fs layer\n",
      "b398e882f414: Waiting\n",
      "67c9f99ecf45: Pulling fs layer\n",
      "dd1646ef8506: Pulling fs layer\n",
      "f2e1f2321196: Waiting\n",
      "237a85b6443b: Pulling fs layer\n",
      "1e87b0a17e1a: Waiting\n",
      "f74bc545f0a3: Pulling fs layer\n",
      "e446a9769f53: Waiting\n",
      "67c9f99ecf45: Waiting\n",
      "dd1646ef8506: Waiting\n",
      "31c18b4a9955: Waiting\n",
      "237a85b6443b: Waiting\n",
      "9d5b560b74d5: Pulling fs layer\n",
      "66a927781c75: Pulling fs layer\n",
      "d237964276af: Pulling fs layer\n",
      "5578e5969293: Pulling fs layer\n",
      "f74bc545f0a3: Waiting\n",
      "66d0708eeaf3: Waiting\n",
      "d237964276af: Waiting\n",
      "5578e5969293: Waiting\n",
      "66a927781c75: Waiting\n",
      "c1bbdc448b72: Verifying Checksum\n",
      "8c3b70e39044: Verifying Checksum\n",
      "8c3b70e39044: Download complete\n",
      "45d437916d57: Download complete\n",
      "d8f1569ddae6: Verifying Checksum\n",
      "d8f1569ddae6: Download complete\n",
      "ee9b457b77d0: Download complete\n",
      "85386706b020: Download complete\n",
      "7ddbc47eeb70: Verifying Checksum\n",
      "7ddbc47eeb70: Download complete\n",
      "7ddbc47eeb70: Pull complete\n",
      "c1bbdc448b72: Pull complete\n",
      "8c3b70e39044: Pull complete\n",
      "45d437916d57: Pull complete\n",
      "d8f1569ddae6: Pull complete\n",
      "85386706b020: Pull complete\n",
      "ee9b457b77d0: Pull complete\n",
      "b398e882f414: Verifying Checksum\n",
      "b398e882f414: Download complete\n",
      "be4f3343ecd3: Verifying Checksum\n",
      "be4f3343ecd3: Download complete\n",
      "f2e1f2321196: Verifying Checksum\n",
      "f2e1f2321196: Download complete\n",
      "e446a9769f53: Download complete\n",
      "1e87b0a17e1a: Verifying Checksum\n",
      "1e87b0a17e1a: Download complete\n",
      "6aadf6f91a8d: Verifying Checksum\n",
      "6aadf6f91a8d: Download complete\n",
      "4493432064f7: Verifying Checksum\n",
      "4493432064f7: Download complete\n",
      "5952336ab5bb: Download complete\n",
      "66d0708eeaf3: Verifying Checksum\n",
      "66d0708eeaf3: Download complete\n",
      "31c18b4a9955: Verifying Checksum\n",
      "31c18b4a9955: Download complete\n",
      "30b4effda4fd: Verifying Checksum\n",
      "30b4effda4fd: Download complete\n",
      "237a85b6443b: Verifying Checksum\n",
      "237a85b6443b: Download complete\n",
      "67c9f99ecf45: Verifying Checksum\n",
      "67c9f99ecf45: Download complete\n",
      "9d5b560b74d5: Verifying Checksum\n",
      "9d5b560b74d5: Download complete\n",
      "66a927781c75: Verifying Checksum\n",
      "66a927781c75: Download complete\n",
      "d237964276af: Verifying Checksum\n",
      "d237964276af: Download complete\n",
      "5578e5969293: Verifying Checksum\n",
      "5578e5969293: Download complete\n",
      "f74bc545f0a3: Verifying Checksum\n",
      "f74bc545f0a3: Download complete\n",
      "dd1646ef8506: Download complete\n",
      "be4f3343ecd3: Pull complete\n",
      "30b4effda4fd: Pull complete\n",
      "b398e882f414: Pull complete\n",
      "f2e1f2321196: Pull complete\n",
      "1e87b0a17e1a: Pull complete\n",
      "e446a9769f53: Pull complete\n",
      "4493432064f7: Pull complete\n",
      "6aadf6f91a8d: Pull complete\n",
      "66d0708eeaf3: Pull complete\n",
      "5952336ab5bb: Pull complete\n",
      "31c18b4a9955: Pull complete\n",
      "67c9f99ecf45: Pull complete\n",
      "dd1646ef8506: Pull complete\n",
      "237a85b6443b: Pull complete\n",
      "f74bc545f0a3: Pull complete\n",
      "9d5b560b74d5: Pull complete\n",
      "66a927781c75: Pull complete\n",
      "d237964276af: Pull complete\n",
      "5578e5969293: Pull complete\n",
      "Digest: sha256:9d52d6d75a74e3891366cc9505dd2bd6e6e1e68766b6167933cce9bd8cbb823a\n",
      "Status: Downloaded newer image for gopalvwsdebb3b12.azurecr.io/azureml/azureml_9125fd9b495cfdec8f7bf56c6d28d91d:latest\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_c02c232e1b37289a0a6f8f779158f57039786cf0db14e945cee0ecc355e45111_d.txt\n",
      "===============================================================================================================\n",
      "\n",
      "Starting job preparation. Current time:2020-03-05T15:58:48.616067\n",
      "Extracting the control code.\n",
      "Creating directory: azureml-logs/\n",
      "Retrieving project from snapshot: 89835c08-c29a-4ca1-b7bc-2e8da031a151\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 78\n",
      "Starting project file download.\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 127\n",
      "Entering Run History Context Manager.\n",
      "Preparing to call script [ script.py ] with arguments: []\n",
      "After variable expansion, calling script [ script.py ] with arguments: []\n",
      "\n",
      "Torch version: 1.4.0\n",
      "Using GPU\n",
      "Downloading: \"https://download.pytorch.org/models/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\" to /root/.cache/torch/checkpoints/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\n",
      "\n",
      "  0%|          | 0.00/170M [00:00<?, ?B/s]\n",
      "  4%|▍         | 6.98M/170M [00:00<00:02, 73.2MB/s]\n",
      "  9%|▉         | 15.8M/170M [00:00<00:02, 78.1MB/s]\n",
      " 14%|█▍        | 23.8M/170M [00:00<00:01, 79.6MB/s]\n",
      " 19%|█▊        | 31.6M/170M [00:00<00:01, 79.7MB/s]\n",
      " 23%|██▎       | 38.8M/170M [00:00<00:01, 78.2MB/s]\n",
      " 27%|██▋       | 45.2M/170M [00:00<00:01, 71.2MB/s]\n",
      " 32%|███▏      | 53.6M/170M [00:00<00:01, 75.5MB/s]\n",
      " 36%|███▌      | 61.5M/170M [00:00<00:01, 77.3MB/s]\n",
      " 40%|████      | 68.6M/170M [00:00<00:01, 75.6MB/s]\n",
      " 45%|████▍     | 75.8M/170M [00:01<00:01, 75.5MB/s]\n",
      " 50%|████▉     | 84.6M/170M [00:01<00:01, 79.6MB/s]\n",
      " 55%|█████▍    | 92.6M/170M [00:01<00:00, 81.0MB/s]\n",
      " 59%|█████▉    | 101M/170M [00:01<00:00, 81.9MB/s] \n",
      " 64%|██████▍   | 108M/170M [00:01<00:00, 81.6MB/s]\n",
      " 69%|██████▊   | 117M/170M [00:01<00:00, 82.9MB/s]\n",
      " 73%|███████▎  | 125M/170M [00:01<00:00, 77.3MB/s]\n",
      " 78%|███████▊  | 132M/170M [00:01<00:00, 78.5MB/s]\n",
      " 82%|████████▏ | 140M/170M [00:01<00:00, 78.0MB/s]\n",
      " 87%|████████▋ | 148M/170M [00:01<00:00, 80.2MB/s]\n",
      " 92%|█████████▏| 157M/170M [00:02<00:00, 81.8MB/s]\n",
      " 97%|█████████▋| 164M/170M [00:02<00:00, 81.2MB/s]\n",
      "100%|██████████| 170M/170M [00:02<00:00, 79.7MB/s]\n",
      "\n",
      "\n",
      "The experiment failed. Finalizing run...\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "3 items cleaning up...\n",
      "Cleanup took 0.0024666786193847656 seconds\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 127\n",
      "Traceback (most recent call last):\n",
      "  File \"script.py\", line 106, in <module>\n",
      "    main()\n",
      "  File \"script.py\", line 93, in main\n",
      "    train_one_epoch(\n",
      "  File \"/mnt/batch/tasks/shared/LS_root/jobs/gopalv-ws/azureml/pytorch-peds_1583423518_e19690b0/mounts/workspaceblobstore/azureml/pytorch-peds_1583423518_e19690b0/engine.py\", line 37, in train_one_epoch\n",
      "    img_loading += (time.time() - t1)\n",
      "UnboundLocalError: local variable 'img_loading' referenced before assignment\n",
      "\n",
      "2020/03/05 16:00:20 mpirun version string: {\n",
      "mpirun (Open MPI) 3.1.2\n",
      "\n",
      "Report bugs to http://www.open-mpi.org/community/help/\n",
      "}\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_c02c232e1b37289a0a6f8f779158f57039786cf0db14e945cee0ecc355e45111_d.txt\n",
      "===============================================================================================================\n",
      "\n",
      "Starting job release. Current time:2020-03-05T16:00:23.458906\n",
      "Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 1617\n",
      "Job release is complete. Current time:2020-03-05T16:00:25.288826\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: pytorch-peds_1583423518_e19690b0\n",
      "Web View: https://mlworkspace.azure.ai/portal/subscriptions/15ae9cb6-95c1-483d-a0e3-b1a1a3b06324/resourceGroups/aifxdemo/providers/Microsoft.MachineLearningServices/workspaces/gopalv-ws/experiments/pytorch-peds/runs/pytorch-peds_1583423518_e19690b0\n",
      "\n",
      "Warnings:\n",
      "{\n",
      "  \"error\": {\n",
      "    \"code\": \"UserError\",\n",
      "    \"message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\",\n",
      "    \"messageFormat\": null,\n",
      "    \"messageParameters\": {},\n",
      "    \"referenceCode\": null,\n",
      "    \"detailsUri\": null,\n",
      "    \"target\": null,\n",
      "    \"details\": [],\n",
      "    \"innerError\": null,\n",
      "    \"debugInfo\": null\n",
      "  },\n",
      "  \"correlation\": {\n",
      "    \"operation\": null,\n",
      "    \"request\": \"0b05f2f57f183658\"\n",
      "  },\n",
      "  \"environment\": \"westus2\",\n",
      "  \"location\": \"westus2\",\n",
      "  \"time\": \"2020-03-05T16:00:42.3925542+00:00\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "ename": "ActivityFailedException",
     "evalue": "ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"User program failed with UnboundLocalError: local variable 'img_loading' referenced before assignment\",\n        \"details\": [],\n        \"debugInfo\": {\n            \"type\": \"UnboundLocalError\",\n            \"message\": \"local variable 'img_loading' referenced before assignment\",\n            \"stackTrace\": \"  File \\\"/mnt/batch/tasks/shared/LS_root/jobs/gopalv-ws/azureml/pytorch-peds_1583423518_e19690b0/mounts/workspaceblobstore/azureml/pytorch-peds_1583423518_e19690b0/azureml-setup/context_manager_injector.py\\\", line 127, in execute_with_context\\n    runpy.run_path(sys.argv[0], globals(), run_name=\\\"__main__\\\")\\n  File \\\"/opt/miniconda/lib/python3.8/runpy.py\\\", line 263, in run_path\\n    return _run_module_code(code, init_globals, run_name,\\n  File \\\"/opt/miniconda/lib/python3.8/runpy.py\\\", line 96, in _run_module_code\\n    _run_code(code, mod_globals, init_globals,\\n  File \\\"/opt/miniconda/lib/python3.8/runpy.py\\\", line 86, in _run_code\\n    exec(code, run_globals)\\n  File \\\"script.py\\\", line 106, in <module>\\n    main()\\n  File \\\"script.py\\\", line 93, in main\\n    train_one_epoch(\\n  File \\\"/mnt/batch/tasks/shared/LS_root/jobs/gopalv-ws/azureml/pytorch-peds_1583423518_e19690b0/mounts/workspaceblobstore/azureml/pytorch-peds_1583423518_e19690b0/engine.py\\\", line 37, in train_one_epoch\\n    img_loading += (time.time() - t1)\\n\"\n        }\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"User program failed with UnboundLocalError: local variable 'img_loading' referenced before assignment\\\",\\n        \\\"details\\\": [],\\n        \\\"debugInfo\\\": {\\n            \\\"type\\\": \\\"UnboundLocalError\\\",\\n            \\\"message\\\": \\\"local variable 'img_loading' referenced before assignment\\\",\\n            \\\"stackTrace\\\": \\\"  File \\\\\\\"/mnt/batch/tasks/shared/LS_root/jobs/gopalv-ws/azureml/pytorch-peds_1583423518_e19690b0/mounts/workspaceblobstore/azureml/pytorch-peds_1583423518_e19690b0/azureml-setup/context_manager_injector.py\\\\\\\", line 127, in execute_with_context\\\\n    runpy.run_path(sys.argv[0], globals(), run_name=\\\\\\\"__main__\\\\\\\")\\\\n  File \\\\\\\"/opt/miniconda/lib/python3.8/runpy.py\\\\\\\", line 263, in run_path\\\\n    return _run_module_code(code, init_globals, run_name,\\\\n  File \\\\\\\"/opt/miniconda/lib/python3.8/runpy.py\\\\\\\", line 96, in _run_module_code\\\\n    _run_code(code, mod_globals, init_globals,\\\\n  File \\\\\\\"/opt/miniconda/lib/python3.8/runpy.py\\\\\\\", line 86, in _run_code\\\\n    exec(code, run_globals)\\\\n  File \\\\\\\"script.py\\\\\\\", line 106, in <module>\\\\n    main()\\\\n  File \\\\\\\"script.py\\\\\\\", line 93, in main\\\\n    train_one_epoch(\\\\n  File \\\\\\\"/mnt/batch/tasks/shared/LS_root/jobs/gopalv-ws/azureml/pytorch-peds_1583423518_e19690b0/mounts/workspaceblobstore/azureml/pytorch-peds_1583423518_e19690b0/engine.py\\\\\\\", line 37, in train_one_epoch\\\\n    img_loading += (time.time() - t1)\\\\n\\\"\\n        }\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\"\\n}\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mActivityFailedException\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-cc0ab15b5cf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mRunDetails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/azureml/lib/python3.6/site-packages/azureml/core/run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[0;34m(self, show_output, wait_post_processing, raise_on_error)\u001b[0m\n\u001b[1;32m    573\u001b[0m                     \u001b[0mfile_handle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m                     \u001b[0mwait_post_processing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait_post_processing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m                     raise_on_error=raise_on_error)\n\u001b[0m\u001b[1;32m    576\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_details\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/azureml/lib/python3.6/site-packages/azureml/core/run.py\u001b[0m in \u001b[0;36m_stream_run_output\u001b[0;34m(self, file_handle, wait_post_processing, raise_on_error)\u001b[0m\n\u001b[1;32m    812\u001b[0m                 \u001b[0mfile_handle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mActivityFailedException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_details\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         \u001b[0mfile_handle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mActivityFailedException\u001b[0m: ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"User program failed with UnboundLocalError: local variable 'img_loading' referenced before assignment\",\n        \"details\": [],\n        \"debugInfo\": {\n            \"type\": \"UnboundLocalError\",\n            \"message\": \"local variable 'img_loading' referenced before assignment\",\n            \"stackTrace\": \"  File \\\"/mnt/batch/tasks/shared/LS_root/jobs/gopalv-ws/azureml/pytorch-peds_1583423518_e19690b0/mounts/workspaceblobstore/azureml/pytorch-peds_1583423518_e19690b0/azureml-setup/context_manager_injector.py\\\", line 127, in execute_with_context\\n    runpy.run_path(sys.argv[0], globals(), run_name=\\\"__main__\\\")\\n  File \\\"/opt/miniconda/lib/python3.8/runpy.py\\\", line 263, in run_path\\n    return _run_module_code(code, init_globals, run_name,\\n  File \\\"/opt/miniconda/lib/python3.8/runpy.py\\\", line 96, in _run_module_code\\n    _run_code(code, mod_globals, init_globals,\\n  File \\\"/opt/miniconda/lib/python3.8/runpy.py\\\", line 86, in _run_code\\n    exec(code, run_globals)\\n  File \\\"script.py\\\", line 106, in <module>\\n    main()\\n  File \\\"script.py\\\", line 93, in main\\n    train_one_epoch(\\n  File \\\"/mnt/batch/tasks/shared/LS_root/jobs/gopalv-ws/azureml/pytorch-peds_1583423518_e19690b0/mounts/workspaceblobstore/azureml/pytorch-peds_1583423518_e19690b0/engine.py\\\", line 37, in train_one_epoch\\n    img_loading += (time.time() - t1)\\n\"\n        }\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"User program failed with UnboundLocalError: local variable 'img_loading' referenced before assignment\\\",\\n        \\\"details\\\": [],\\n        \\\"debugInfo\\\": {\\n            \\\"type\\\": \\\"UnboundLocalError\\\",\\n            \\\"message\\\": \\\"local variable 'img_loading' referenced before assignment\\\",\\n            \\\"stackTrace\\\": \\\"  File \\\\\\\"/mnt/batch/tasks/shared/LS_root/jobs/gopalv-ws/azureml/pytorch-peds_1583423518_e19690b0/mounts/workspaceblobstore/azureml/pytorch-peds_1583423518_e19690b0/azureml-setup/context_manager_injector.py\\\\\\\", line 127, in execute_with_context\\\\n    runpy.run_path(sys.argv[0], globals(), run_name=\\\\\\\"__main__\\\\\\\")\\\\n  File \\\\\\\"/opt/miniconda/lib/python3.8/runpy.py\\\\\\\", line 263, in run_path\\\\n    return _run_module_code(code, init_globals, run_name,\\\\n  File \\\\\\\"/opt/miniconda/lib/python3.8/runpy.py\\\\\\\", line 96, in _run_module_code\\\\n    _run_code(code, mod_globals, init_globals,\\\\n  File \\\\\\\"/opt/miniconda/lib/python3.8/runpy.py\\\\\\\", line 86, in _run_code\\\\n    exec(code, run_globals)\\\\n  File \\\\\\\"script.py\\\\\\\", line 106, in <module>\\\\n    main()\\\\n  File \\\\\\\"script.py\\\\\\\", line 93, in main\\\\n    train_one_epoch(\\\\n  File \\\\\\\"/mnt/batch/tasks/shared/LS_root/jobs/gopalv-ws/azureml/pytorch-peds_1583423518_e19690b0/mounts/workspaceblobstore/azureml/pytorch-peds_1583423518_e19690b0/engine.py\\\\\\\", line 37, in train_one_epoch\\\\n    img_loading += (time.time() - t1)\\\\n\\\"\\n        }\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\"\\n}\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get your latest run and register your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Run\n",
    "\n",
    "run = Run(run_id='pytorch-peds_1583262435_ac3ea423', experiment=experiment)\n",
    "model = run.register_model(model_name='pytorch_peds', model_path='outputs/model.pt')\n",
    "model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "path = model.download(target_dir='.', exist_ok=True)\n",
    "path\n",
    "\n",
    "# model = torch.load(path)\n",
    "#torch.load(model.get_model_path(model_name='outputs/model.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from azureml.core import Dataset\n",
    "from data import PennFudanDataset\n",
    "from script import get_transform\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model = torch.load('./model.pt', map_location=device)\n",
    "\n",
    "penn_ds = Dataset.get_by_name(workspace=ws, name='penn_ds')\n",
    "dataset_test = PennFudanDataset(penn_ds, get_transform(train=False))\n",
    "\n",
    "\n",
    "\n",
    "# pick one image from the test set\n",
    "img, _ = dataset_test[0]\n",
    "# put the model in evaluation mode\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = model([img.to(device)])"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "azureml",
   "language": "python",
   "name": "azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
