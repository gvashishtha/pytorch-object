{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection with PyTorch and Mask R-CNN \n",
    "\n",
    "In this tutorial, you will finetune a pre-trained [Mask R-CNN](https://arxiv.org/abs/1703.06870) model on images from the [Penn-Fudan Database for Pedestrian Detection and Segmentation](https://www.cis.upenn.edu/~jshi/ped_html/). The dataset has 170 images with 345 instances of pedestrians.\n",
    "\n",
    "## Prerequisities\n",
    "\n",
    "- If you are using an Azure Machine Learning Notebook VM, your environment already meets these prerequisites. Otherwise, go through the [Configuration](https://docs.microsoft.com/azure/machine-learning/how-to-configure-environment) steps to install the Azure Machine Learning Python SDK and [create an Azure ML Workspace](https://docs.microsoft.com/azure/machine-learning/how-to-manage-workspace#create-a-workspace).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint hyperdrive = azureml.train.hyperdrive:HyperDriveRun._from_run_dto with exception (azureml-core 1.0.65.1 (/home/gopalv/miniconda3/envs/azureml/lib/python3.6/site-packages), Requirement.parse('azureml-core==1.0.69.*')).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.PipelineRun = azureml.pipeline.core.run:PipelineRun._from_dto with exception (azureml-core 1.0.65.1 (/home/gopalv/miniconda3/envs/azureml/lib/python3.6/site-packages), Requirement.parse('azureml-core==1.0.69.*')).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.ReusedStepRun = azureml.pipeline.core.run:StepRun._from_reused_dto with exception (azureml-core 1.0.65.1 (/home/gopalv/miniconda3/envs/azureml/lib/python3.6/site-packages), Requirement.parse('azureml-core==1.0.69.*')).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.StepRun = azureml.pipeline.core.run:StepRun._from_dto with exception (azureml-core 1.0.65.1 (/home/gopalv/miniconda3/envs/azureml/lib/python3.6/site-packages), Requirement.parse('azureml-core==1.0.69.*')).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.0.65\n"
     ]
    }
   ],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostics\n",
    "\n",
    "Opt-in diagnostics for better experience, quality, and security in future releases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turning diagnostics collection on. \n"
     ]
    }
   ],
   "source": [
    "from azureml.telemetry import set_diagnostics_collection\n",
    "\n",
    "set_diagnostics_collection(send_diagnostics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize a workspace\n",
    "\n",
    "Initialize a [workspace](https://docs.microsoft.com/en-us/azure/machine-learning/concept-workspace) object from the existing workspace you created in the Prerequisites step. `Workspace.from_config()` creates a workspace object from the details stored in `config.json`, using the [from_config()](https://docs.microsoft.com/python/api/azureml-core/azureml.core.workspace(class)?view=azure-ml-py#from-config-path-none--auth-none---logger-none---file-name-none-) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: gopalv-ws\n",
      "Azure region: westus2\n",
      "Subscription id: 15ae9cb6-95c1-483d-a0e3-b1a1a3b06324\n",
      "Resource group: aifxdemo\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create or attach existing Azure ML Managed Compute\n",
    "\n",
    "You will need to create a [compute target](https://docs.microsoft.com/azure/machine-learning/concept-compute-target) for training your model. In this tutorial, we use [Azure ML managed compute](https://docs.microsoft.com/azure/machine-learning/how-to-set-up-training-targets#amlcompute) for our remote training compute resource. Specifically, the below code creates a `STANDARD_NC6` GPU cluster that autoscales from 0 to 4 nodes.\n",
    "\n",
    "**Creation of Compute takes approximately 5 minutes.** If the Aauzre ML Compute with that name is already in your workspace, this code will skip the creation process. \n",
    "\n",
    "As with other Azure servies, there are limits on certain resources associated with the Azure Machine Learning service. Please read [this article](https://docs.microsoft.com/azure/machine-learning/how-to-manage-quotas) on the default limits and how to request more quota.\n",
    "\n",
    "> Note that the below code creates GPU compute. If you instead want to create CPU compute, provide a different VM size to the `vm_size` parameter, such as `STANDARD_D2_V2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['demouser', 'demo@pass123']\n",
      "Found existing compute target.\n",
      "{'currentNodeCount': 1, 'targetNodeCount': 1, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 1, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2020-03-05T16:21:52.965000+00:00', 'errors': None, 'creationTime': '2020-03-05T14:55:28.441267+00:00', 'modifiedTime': '2020-03-05T15:05:30.544256+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_NC6'}\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# Avoid committing username and password in Git history, useful for debugging GPU usage\n",
    "\n",
    "login_strings = []\n",
    "with open('username-pass.txt', 'r') as file:\n",
    "    for line in file.readlines():\n",
    "        login_strings.append(line.rstrip('\\n'))\n",
    "\n",
    "print(login_strings)\n",
    "\n",
    "# choose a name for your cluster\n",
    "cluster_name = 'gpu-cluster'\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing compute target.')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC6', \n",
    "                                                           max_nodes=4,\n",
    "                                                           admin_username=login_strings[0],\n",
    "                                                           admin_user_password=login_strings[1])\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "    compute_target.wait_for_completion(show_output=True)\n",
    "\n",
    "# use get_status() to get a detailed status for the current cluster. \n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model on the remote compute\n",
    "\n",
    "### Create a project directory\n",
    "Create a directory that will contain all the code from your local machine that you will need access to on the remote resource. This includes the training script an any additional files your training script depends on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project folder ./pytorch-peds exists, moving on...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "project_folder = './pytorch-peds'\n",
    "\n",
    "try:\n",
    "    os.makedirs(project_folder, exist_ok=False)\n",
    "except FileExistsError:\n",
    "    print(f'project folder {project_folder} exists, moving on...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possibly helpful: [this link](https://github.com/drabastomek/GTC/blob/master/SJ_2020/workshop/1_Setup/Setup.ipynb), and this sample dockerfile from Jordan:\n",
    "\n",
    "```\n",
    "FROM mcr.microsoft.com/azureml/base-gpu:intelmpi2018.3-cuda9.0-cudnn7-ubuntu16.04\n",
    "\n",
    "# Install Horovod, temporarily using CUDA stubsddd \n",
    "RUN ldconfig /usr/local/cuda/lib64/stubs && \\     \n",
    "# Install AzureML SDK     \n",
    "pip install --no-cache-dir azureml-defaults && \\     \n",
    "# Install PyTorch     \n",
    "pip install --no-cache-dir tensorflow==2.0.0b1 tensorflow-gpu==2.0.0b1 keras==2.0.8 matplotlib==3.0.3 seaborn==0.9.0 requests==2.21.0 bs4==0.0.1 imageio==2.5.0 sklearn pandas==0.24.2 numpy==1.16.2 hickle==3.4.3 && \\     \n",
    "# Install Horovod     \n",
    "pip install --no-cache-dir horovod==0.13.5 && \\     ldconfig\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy training script and dependencies into project directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./pytorch-peds/script.py'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.copy('data.py', project_folder)\n",
    "shutil.copy('model.py', project_folder)\n",
    "shutil.copy('script.py', project_folder)\n",
    "\n",
    "files_to_copy = ['utils', 'transforms', 'coco_eval', 'engine', 'coco_utils']\n",
    "for file in files_to_copy:\n",
    "    shutil.copy('./'+ file + '.py', project_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/pytorch/vision.git\n",
    "\n",
    "# !git checkout v0.3.0\n",
    "\n",
    "# %cd vision\n",
    "# !cp references/detection/utils.py ../\n",
    "# !cp references/detection/transforms.py ../\n",
    "# !cp references/detection/coco_eval.py ../\n",
    "# !cp references/detection/engine.py ../\n",
    "# !cp references/detection/coco_utils.py ../\n",
    "# %cd ..\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data and upload to Azure blob storage\n",
    "\n",
    "First we download the sample dataset, and extract the images into local storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation  PNGImages  PedMasks  added-object-list.txt\treadme.txt\r\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "from zipfile import ZipFile\n",
    "\n",
    "data_file = './test.zip'\n",
    "\n",
    "urllib.request.urlretrieve('https://www.cis.upenn.edu/~jshi/ped_html/PennFudanPed.zip', data_file)\n",
    "zip = ZipFile(file=data_file)\n",
    "zip.extractall()\n",
    "!ls PennFudanPed/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we upload the data files to the datastore associated with this workspace, so that we can access them during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workspaceblobstore AzureBlob gopalvws3790775563 azureml-blobstore-e47496c6-9688-4277-a05b-ceb722514b9d\n",
      "Uploading an estimated of 512 files\n",
      "Target already exists. Skipping upload for data/added-object-list.txt\n",
      "Target already exists. Skipping upload for data/readme.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00001.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00002.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00003.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00004.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00005.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00006.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00007.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00008.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00009.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00010.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00011.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00012.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00013.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00014.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00015.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00016.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00017.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00018.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00019.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00020.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00021.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00022.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00023.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00024.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00025.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00026.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00027.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00028.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00029.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00030.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00031.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00032.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00033.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00034.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00035.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00036.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00037.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00038.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00039.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00040.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00041.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00042.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00043.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00044.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00045.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00046.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00047.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00048.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00049.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00050.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00051.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00052.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00053.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00054.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00055.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00056.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00057.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00058.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00059.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00060.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00061.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00062.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00063.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00064.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00065.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00066.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00067.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00068.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00069.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00070.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00071.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00072.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00073.txt\n",
      "Target already exists. Skipping upload for data/Annotation/FudanPed00074.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00001.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00002.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00003.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00004.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00005.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00006.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00007.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00008.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00009.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00010.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00011.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00012.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00013.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00014.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00015.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00016.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00017.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00018.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00019.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00020.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00021.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00022.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00023.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00024.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00025.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00026.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00027.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00028.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00029.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00030.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00031.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00032.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00033.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00034.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00035.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00036.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00037.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target already exists. Skipping upload for data/Annotation/PennPed00038.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00039.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00040.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00041.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00042.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00043.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00044.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00045.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00046.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00047.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00048.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00049.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00050.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00051.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00052.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00053.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00054.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00055.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00056.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00057.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00058.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00059.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00060.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00061.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00062.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00063.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00064.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00065.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00066.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00067.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00068.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00069.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00070.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00071.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00072.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00073.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00074.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00075.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00076.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00077.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00078.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00079.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00080.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00081.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00082.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00083.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00084.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00085.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00086.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00087.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00088.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00089.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00090.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00091.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00092.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00093.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00094.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00095.txt\n",
      "Target already exists. Skipping upload for data/Annotation/PennPed00096.txt\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00001.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00002.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00003.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00004.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00005.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00006.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00007.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00008.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00009.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00010.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00011.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00012.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00013.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00014.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00015.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00016.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00017.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00018.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00019.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00020.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00021.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00022.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00023.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00024.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00025.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00026.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00027.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00028.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00029.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00030.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00031.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00032.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00033.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00034.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00035.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00036.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00037.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00038.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00039.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00040.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00041.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00042.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00043.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00044.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00045.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00046.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00047.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00048.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00049.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00050.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00051.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00052.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00053.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00054.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00055.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00056.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00057.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00058.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00059.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00060.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00061.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00062.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00063.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00064.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00065.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00066.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00067.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00068.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00069.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00070.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00071.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00072.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00073.png\n",
      "Target already exists. Skipping upload for data/PNGImages/FudanPed00074.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00001.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00002.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00003.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00004.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00005.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00006.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00007.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00008.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00009.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00010.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00011.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00012.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00013.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00014.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00015.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00016.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00017.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00018.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00019.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00020.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00021.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00022.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00023.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00024.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00025.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00026.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00027.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00028.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00029.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00030.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00031.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00032.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00033.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00034.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00035.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00036.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00037.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00038.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00039.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00040.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00041.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00042.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00043.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00044.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00045.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00046.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00047.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00048.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00049.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00050.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00051.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00052.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00053.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00054.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00055.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00056.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00057.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00058.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00059.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00060.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00061.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00062.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00063.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00064.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00065.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00066.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00067.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00068.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00069.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00070.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00071.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00072.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00073.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00074.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00075.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00076.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00077.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00078.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00079.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00080.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00081.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00082.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00083.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00084.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00085.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00086.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target already exists. Skipping upload for data/PNGImages/PennPed00087.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00088.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00089.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00090.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00091.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00092.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00093.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00094.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00095.png\n",
      "Target already exists. Skipping upload for data/PNGImages/PennPed00096.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00001_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00002_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00003_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00004_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00005_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00006_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00007_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00008_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00009_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00010_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00011_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00012_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00013_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00014_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00015_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00016_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00017_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00018_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00019_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00020_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00021_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00022_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00023_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00024_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00025_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00026_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00027_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00028_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00029_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00030_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00031_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00032_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00033_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00034_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00035_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00036_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00037_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00038_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00039_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00040_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00041_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00042_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00043_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00044_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00045_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00046_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00047_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00048_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00049_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00050_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00051_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00052_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00053_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00054_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00055_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00056_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00057_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00058_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00059_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00060_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00061_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00062_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00063_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00064_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00065_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00066_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00067_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00068_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00069_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00070_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00071_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00072_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00073_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/FudanPed00074_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00001_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00002_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00003_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00004_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00005_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00006_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00007_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00008_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00009_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00010_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00011_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00012_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00013_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00014_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00015_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00016_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00017_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00018_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00019_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00020_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00021_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00022_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00023_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00024_mask.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target already exists. Skipping upload for data/PedMasks/PennPed00025_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00026_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00027_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00028_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00029_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00030_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00031_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00032_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00033_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00034_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00035_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00036_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00037_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00038_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00039_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00040_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00041_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00042_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00043_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00044_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00045_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00046_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00047_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00048_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00049_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00050_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00051_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00052_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00053_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00054_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00055_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00056_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00057_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00058_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00059_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00060_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00061_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00062_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00063_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00064_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00065_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00066_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00067_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00068_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00069_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00070_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00071_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00072_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00073_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00074_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00075_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00076_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00077_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00078_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00079_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00080_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00081_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00082_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00083_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00084_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00085_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00086_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00087_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00088_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00089_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00090_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00091_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00092_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00093_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00094_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00095_mask.png\n",
      "Target already exists. Skipping upload for data/PedMasks/PennPed00096_mask.png\n",
      "Uploaded 0 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_a3b34009c18b402781d977ec39f7096f"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the default datastore\n",
    "ds = ws.get_default_datastore()\n",
    "print(ds.name, ds.datastore_type, ds.account_name, ds.container_name)\n",
    "\n",
    "ds.upload('./PennFudanPed', target_path='data', overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register a dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"source\": [\n",
       "    \"('workspaceblobstore', 'data')\"\n",
       "  ],\n",
       "  \"definition\": [\n",
       "    \"GetDatastoreFiles\"\n",
       "  ],\n",
       "  \"registration\": {\n",
       "    \"name\": \"penn_ds\",\n",
       "    \"version\": 1,\n",
       "    \"description\": \"Penn Fudan pedestrian data\",\n",
       "    \"workspace\": \"Workspace.create(name='gopalv-ws', subscription_id='15ae9cb6-95c1-483d-a0e3-b1a1a3b06324', resource_group='aifxdemo')\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "datastore_paths = [(ds, 'data')]\n",
    "penn_ds = Dataset.File.from_files(path=datastore_paths)\n",
    "penn_ds.register(workspace=ws,\n",
    "                 name='penn_ds',\n",
    "                 description='Penn Fudan pedestrian data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment_name = 'pytorch-peds'\n",
    "experiment = Experiment(ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify dependencies with a custom Dockerfile\n",
    "\n",
    "There are a number of ways to [use environments](https://docs.microsoft.com/azure/machine-learning/how-to-use-environments) for specifying dependencies during model training. In this case, we use a custom Dockerfile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 'gpu_support' is no longer necessary; AzureML now automatically detects and uses nvidia docker extension when it is available. It will be removed in a future release.\n",
      "WARNING - 'gpu_support' is no longer necessary; AzureML now automatically detects and uses nvidia docker extension when it is available. It will be removed in a future release.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Environment\n",
    "\n",
    "my_env = Environment(name='maskr-docker')\n",
    "my_env.docker.enabled = True\n",
    "with open(\"dockerfiles/Dockerfile1\", \"r\") as f:\n",
    "    dockerfile_contents_of_your_base_image=f.read()\n",
    "my_env.docker.base_dockerfile=dockerfile_contents_of_your_base_image \n",
    "my_env.docker.base_image = None\n",
    "my_env.docker.gpu_support = True\n",
    "my_env.python.interpreter_path = '/opt/miniconda/bin/python'\n",
    "my_env.python.user_managed_dependencies = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a ScriptRunConfig\n",
    "\n",
    "Use the [ScriptRunConfig](https://docs.microsoft.com/python/api/azureml-core/azureml.core.scriptrunconfig?view=azure-ml-py) class to define your run. Specify the source driectory, compute target, and environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.dnn import PyTorch\n",
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "# follow pattern from here: https://docs.microsoft.com/en-us/azure/machine-learning/how-to-use-environments#use-environments-for-training\n",
    "\n",
    "# Add training script to run config\n",
    "runconfig = ScriptRunConfig(source_directory=project_folder, script=\"script.py\")\n",
    "\n",
    "# Attach compute target to run config\n",
    "runconfig.run_config.target = cluster_name\n",
    "\n",
    "# Uncomment the line below if you want to try this locally first\n",
    "#runconfig.run_config.target = \"local\"\n",
    "\n",
    "# Attach environment to run config\n",
    "runconfig.run_config.environment = my_env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit your run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'runId': 'pytorch-peds_1583446986_325bdc5c', 'target': 'gpu-cluster', 'status': 'Starting', 'properties': {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': '622a759f-97d4-4e2f-a589-0abd1e4b79ef', 'azureml.git.repository_uri': 'git@github.com:gvashishtha/pytorch-object.git', 'mlflow.source.git.repoURL': 'git@github.com:gvashishtha/pytorch-object.git', 'azureml.git.branch': 'dataset-change', 'mlflow.source.git.branch': 'dataset-change', 'azureml.git.commit': '5b39a0f082ec9e5a099db28f6879900279d0386d', 'mlflow.source.git.commit': '5b39a0f082ec9e5a099db28f6879900279d0386d', 'azureml.git.dirty': 'False', 'AzureML.DerivedImageName': 'azureml/azureml_9125fd9b495cfdec8f7bf56c6d28d91d'}, 'inputDatasets': [], 'runDefinition': {'script': 'script.py', 'useAbsolutePath': False, 'arguments': [], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'gpu-cluster', 'dataReferences': {}, 'data': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'environment': {'name': 'maskr-docker', 'version': 'Autosave_2020-02-29T00:36:31Z_cd1e72fb', 'python': {'interpreterPath': '/opt/miniconda/bin/python', 'userManagedDependencies': True, 'condaDependencies': {'name': 'project_environment', 'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults']}], 'channels': ['conda-forge']}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': None, 'baseDockerfile': '# From https://github.com/microsoft/AzureML-BERT/blob/master/finetune/PyTorch/dockerfile\\n\\nFROM mcr.microsoft.com/azureml/base-gpu:openmpi3.1.2-cuda10.1-cudnn7-ubuntu18.04\\n\\nRUN apt update && apt install git -y && rm -rf /var/lib/apt/lists/*\\n\\nRUN /opt/miniconda/bin/conda update -n base -c defaults conda\\nRUN /opt/miniconda/bin/conda install -y cython=0.29.15 numpy=1.18.1\\nRUN /opt/miniconda/bin/conda install -y pytorch=1.4 torchvision=0.5.0 -c pytorch\\n\\n# Install cocoapi, required for drawing bounding boxes\\nRUN git clone https://github.com/cocodataset/cocoapi.git && cd cocoapi/PythonAPI && python setup.py build_ext install\\n\\nRUN pip install azureml-defaults\\nRUN pip install \"azureml-dataprep[fuse]\"\\nRUN pip install pandas pyarrow\\n', 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}}, 'logFiles': {}}\n"
     ]
    }
   ],
   "source": [
    "# Submit run \n",
    "run = experiment.submit(runconfig)\n",
    "\n",
    "# to get more details of your run\n",
    "print(run.get_details())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor your run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "284275d20b56464b922a469ae9a6e988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': True, 'log_level': 'INFO', 's"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: pytorch-peds_1583446986_325bdc5c\n",
      "Web View: https://mlworkspace.azure.ai/portal/subscriptions/15ae9cb6-95c1-483d-a0e3-b1a1a3b06324/resourceGroups/aifxdemo/providers/Microsoft.MachineLearningServices/workspaces/gopalv-ws/experiments/pytorch-peds/runs/pytorch-peds_1583446986_325bdc5c\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: pytorch-peds_1583446986_325bdc5c\n",
      "Web View: https://mlworkspace.azure.ai/portal/subscriptions/15ae9cb6-95c1-483d-a0e3-b1a1a3b06324/resourceGroups/aifxdemo/providers/Microsoft.MachineLearningServices/workspaces/gopalv-ws/experiments/pytorch-peds/runs/pytorch-peds_1583446986_325bdc5c\n"
     ]
    },
    {
     "ename": "ActivityFailedException",
     "evalue": "ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"ServiceError\",\n        \"message\": \"AzureMLCompute job failed.\\nJobPreparationError: failed to prepare an environment for the job execution\\n\\tInfo: Job environment preparation failed on 10.0.0.4.\",\n        \"details\": []\n    },\n    \"correlation\": {\n        \"operation\": null,\n        \"request\": \"6e32ed02991646ab\"\n    },\n    \"environment\": \"westus2\",\n    \"location\": \"westus2\",\n    \"time\": \"2020-03-05T22:30:51.379442Z\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"ServiceError\\\",\\n        \\\"message\\\": \\\"AzureMLCompute job failed.\\\\nJobPreparationError: failed to prepare an environment for the job execution\\\\n\\\\tInfo: Job environment preparation failed on 10.0.0.4.\\\",\\n        \\\"details\\\": []\\n    },\\n    \\\"correlation\\\": {\\n        \\\"operation\\\": null,\\n        \\\"request\\\": \\\"6e32ed02991646ab\\\"\\n    },\\n    \\\"environment\\\": \\\"westus2\\\",\\n    \\\"location\\\": \\\"westus2\\\",\\n    \\\"time\\\": \\\"2020-03-05T22:30:51.379442Z\\\"\\n}\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mActivityFailedException\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-cc0ab15b5cf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mRunDetails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/azureml/lib/python3.6/site-packages/azureml/core/run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[0;34m(self, show_output, wait_post_processing, raise_on_error)\u001b[0m\n\u001b[1;32m    573\u001b[0m                     \u001b[0mfile_handle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m                     \u001b[0mwait_post_processing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait_post_processing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m                     raise_on_error=raise_on_error)\n\u001b[0m\u001b[1;32m    576\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_details\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/azureml/lib/python3.6/site-packages/azureml/core/run.py\u001b[0m in \u001b[0;36m_stream_run_output\u001b[0;34m(self, file_handle, wait_post_processing, raise_on_error)\u001b[0m\n\u001b[1;32m    812\u001b[0m                 \u001b[0mfile_handle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mActivityFailedException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_details\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         \u001b[0mfile_handle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mActivityFailedException\u001b[0m: ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"ServiceError\",\n        \"message\": \"AzureMLCompute job failed.\\nJobPreparationError: failed to prepare an environment for the job execution\\n\\tInfo: Job environment preparation failed on 10.0.0.4.\",\n        \"details\": []\n    },\n    \"correlation\": {\n        \"operation\": null,\n        \"request\": \"6e32ed02991646ab\"\n    },\n    \"environment\": \"westus2\",\n    \"location\": \"westus2\",\n    \"time\": \"2020-03-05T22:30:51.379442Z\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"ServiceError\\\",\\n        \\\"message\\\": \\\"AzureMLCompute job failed.\\\\nJobPreparationError: failed to prepare an environment for the job execution\\\\n\\\\tInfo: Job environment preparation failed on 10.0.0.4.\\\",\\n        \\\"details\\\": []\\n    },\\n    \\\"correlation\\\": {\\n        \\\"operation\\\": null,\\n        \\\"request\\\": \\\"6e32ed02991646ab\\\"\\n    },\\n    \\\"environment\\\": \\\"westus2\\\",\\n    \\\"location\\\": \\\"westus2\\\",\\n    \\\"time\\\": \\\"2020-03-05T22:30:51.379442Z\\\"\\n}\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get your latest run and register your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Run\n",
    "\n",
    "run = Run(run_id='pytorch-peds_1583262435_ac3ea423', experiment=experiment)\n",
    "model = run.register_model(model_name='pytorch_peds', model_path='outputs/model.pt')\n",
    "model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "path = model.download(target_dir='.', exist_ok=True)\n",
    "path\n",
    "\n",
    "# model = torch.load(path)\n",
    "#torch.load(model.get_model_path(model_name='outputs/model.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from azureml.core import Dataset\n",
    "from data import PennFudanDataset\n",
    "from script import get_transform\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model = torch.load('./model.pt', map_location=device)\n",
    "\n",
    "penn_ds = Dataset.get_by_name(workspace=ws, name='penn_ds')\n",
    "dataset_test = PennFudanDataset(penn_ds, get_transform(train=False))\n",
    "\n",
    "\n",
    "\n",
    "# pick one image from the test set\n",
    "img, _ = dataset_test[0]\n",
    "# put the model in evaluation mode\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = model([img.to(device)])"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "azureml",
   "language": "python",
   "name": "azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
